{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88274f6",
   "metadata": {},
   "source": [
    "###  actual model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee209bd",
   "metadata": {},
   "source": [
    "### Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82873362",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)   # refer to Note #3 for synthetic_data method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de17021",
   "metadata": {},
   "source": [
    "### Selecting the dataset in batches for minibatch stochastic gradient descent using pytorch data util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True): #@save\n",
    "    \"\"\"\n",
    "    creates pytorch data iterator for the given batch size\n",
    "    \"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e845af",
   "metadata": {},
   "source": [
    "#### testing the batch_size loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "batch_data_loader = load_array([features, labels], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(batch_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab94ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(batch_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_iter)    # iterator, gives batch_size of data on each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14774f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe43729",
   "metadata": {},
   "source": [
    "### defining the linear model using pytorch avaiable API's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7dce3",
   "metadata": {},
   "source": [
    "#### using \"Sequential\" class from NeuralNet (\"nn\") module.\n",
    "#### Sequential class defines container for several layers to be chained together.\n",
    "#### a Sequential instance passes the given input through the first layer, and then in turn passing the output as the second layer ºs input and so on until all the chained layers.\n",
    "#### we need only one layer in this model. \n",
    "#### We also need the layer to be fully connected. ( every input connected to the output)\n",
    "\n",
    "#### \"Linear\" class from nn module can be used to create fully connected layer, the arguments indicates the dimensions of input and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn # Neural Networks\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))  # 2 inputs (x1, x2) and one output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff9cc2",
   "metadata": {},
   "source": [
    "### selecting initial model parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc14ef",
   "metadata": {},
   "source": [
    "#### from the neuralnet object, we can directly set the weight and bias params, using the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net[0].weight.data.normal_(0, 0.1)   # '0' indicates the first layer in the network\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd5d72",
   "metadata": {},
   "source": [
    "### defining the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d594df0",
   "metadata": {},
   "source": [
    "#### using Mean Squared Error loss from the nn library, \n",
    "#### note: by deafult, it uses the reduction method as 'mean', meaning normalizing the loss by the length of input.\n",
    "#### to change this, we can use the keywordargument 'reduction' as sum (nn.MSELoss(reduction=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()  # using the MeanSquaredError "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63d50b",
   "metadata": {},
   "source": [
    "### defining the model optimizing algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6da08",
   "metadata": {},
   "source": [
    "#### we can use the 'optim' module of pytorch to get the Stochasitic Gradient descent algorithm\n",
    "#### it can take key value pairs of hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab29f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03) # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b952ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46695d",
   "metadata": {},
   "source": [
    "#### the step method from SGD can be used for updating model params for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd4bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(trainer.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            l = loss(net(X), y)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        training_loss = loss(net(features), labels)\n",
    "\n",
    "        print(f'epoch {epoch + 1}, loss {training_loss:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62077a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4fd3e",
   "metadata": {},
   "source": [
    "#### the final parameters gets updated in the neural network object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a133e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_error():\n",
    "    w_estimated = net[0].weight.data\n",
    "    b_estimated = net[0].bias.data\n",
    "    \n",
    "    print('error in estimating w:', true_w - w_estimated.reshape(true_w.shape))\n",
    "    print('error in estimating b:', true_b - b_estimated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793319d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe32be",
   "metadata": {},
   "source": [
    "### With using HuberLoss method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7f780",
   "metadata": {},
   "source": [
    "#### HuberLoss - uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_error()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
